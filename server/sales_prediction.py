# -*- coding: utf-8 -*-
"""sales_prediction_model__v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ftvdpXXRLAhqfmOBzCMfU4r4pJIbN0b9
"""

import numpy as np
import pandas as pd
import csv

def predict():
    df = pd.read_csv('db2.0.csv')
    df.rename(columns={'data': 'date', 'somma_polli': 'sales', 'feste': 'holidays', 'fenomeni': 'weather'}, inplace=True)
    df.date = pd.to_datetime(df.date)

    df.info()

    df.head()

    """## Cleaning Days"""

    df.dayname.value_counts()

    """Delate Mondays"""
    df.drop(index=df.query("dayname == 'lunedì'").index, inplace=True)


    """# Dataset"""

    dataset = df[['sales',
                  't_media',
                  't_min',
                  'umidità_percentuale',
                  'juventus',
                  'weather',
                  'holidays']].copy()

    """## Day - Month"""

    def cyclical_feature_encoding(feature, max_val):
        tmp = 2 * np.pi * feature / float(max_val)
        return pd.Series(np.sin(tmp), name=f'{feature.name}_sin'), pd.Series(np.cos(tmp), name=f'{feature.name}_cos')


    dataset['day_sin'], dataset['day_cos'] = cyclical_feature_encoding(df.date.dt.dayofweek, max_val=6)
    dataset['month_sin'], dataset['month_cos'] = cyclical_feature_encoding(df.date.dt.month, max_val=12)

    """## Teams"""

    dataset.juventus = dataset.juventus.apply(lambda x: 0 if x == '0' else 1)

    """## Lag"""

    lag_window = [1, 5, 6, 7, 11, 12, 13]
    lag_columns = ['sales', 'weather', 'juventus', 'holidays']

    for lag in lag_window:
        for col in lag_columns:
            dataset[f'lag{lag}_{col}'] = dataset[col].shift(lag)

    dataset = dataset.iloc[max(lag_window):]

    """## Holidays"""

    dataset.holidays.unique()

    dataset = pd.concat([dataset, pd.get_dummies(dataset.holidays, dummy_na=False)], axis=1)
    dataset.drop(columns=['holidays'], inplace=True)

    for lag in lag_window:
        col = f'lag{lag}_holidays'
        dataset = pd.concat([dataset, pd.get_dummies(dataset[col], dummy_na=False, prefix=f'lag{lag}')], axis=1)
        dataset.drop(columns=[col], inplace=True)

    dataset.columns.tolist()

    """## Weather"""

    df.weather.unique()

    dataset = pd.concat([dataset, pd.get_dummies(dataset.weather, drop_first=True, dummy_na=False)], axis=1)
    dataset.drop(columns=['weather'], inplace=True)

    for lag in lag_window:
        col = f'lag{lag}_weather'
        dataset = pd.concat([dataset, pd.get_dummies(dataset[col], drop_first=True, dummy_na=False, prefix=f'lag{lag}')], axis=1)
        dataset.drop(columns=[col], inplace=True)

    """# Basic Model - Linear Regression"""

    from sklearn.linear_model import Ridge
    from sklearn.model_selection import TimeSeriesSplit, cross_val_score, RandomizedSearchCV

    TEST_SIZE = 0.15

    X = dataset.drop(columns=['sales'])
    y = dataset.sales

    split_idx = dataset.iloc[int(len(dataset)*(1-TEST_SIZE))].name

    X_train, X_test = X.loc[:split_idx], X.loc[split_idx:]
    y_train, y_test = y.loc[:split_idx], y.loc[split_idx:]

    sample_weights = [np.exp(t/float(len(y_train))) for t in range(len(y_train))]

    model = Ridge()

    hyperparameters = {'alpha': np.linspace(start=0., stop=50., num=50)}

    random_search = RandomizedSearchCV(estimator=model,
                                       param_distributions=hyperparameters,
                                       n_iter=50,
                                       cv=TimeSeriesSplit(n_splits=10),
                                       n_jobs=-1)

    random_search.fit(X_train, y_train, sample_weight=sample_weights)

    random_search.cv_results_['mean_test_score']

    random_search.best_params_

    from sklearn.model_selection import cross_val_score

    cross_val_score(estimator=model,
                    X=X_train,
                    y=y_train,
                    cv=TimeSeriesSplit(n_splits=10),
                    n_jobs=-1)

    best_model = random_search.best_estimator_

    pred = np.round(best_model.predict(X_test))

    """## Prediction Error"""

    results = pd.DataFrame({'date': df.loc[split_idx:, 'date'], 'y_true': y_test.values, 'y_pred': pred})

    results.head()

    results['residuals'] = results.y_true - results.y_pred
    results['abs_res'] = results.residuals.abs()
    results['mae'] = results.abs_res / results.y_true

    results.sort_values(by=['abs_res'], ascending=False, inplace=True)

    results = pd.merge(left=results, right=df, on='date')

    results.holidays.fillna('#', inplace=True)

    colonne = results.copy()

    colonne.sort_values(by=["date"], ascending=True, inplace=True)

    colonne = colonne[['date', 'y_true', 'y_pred']]

    dates = pd.to_datetime(colonne['date']).dt.date.unique().tolist()
    prediction = colonne['y_pred'].tolist()
    sales = colonne['y_true'].tolist()

    dates = [d.isoformat() for d in dates]

    colonne_filtered = {
        'dates': dates,
        'prediction': prediction,
        'sales': sales
    }

    return colonne_filtered

def save_prediction():
    colonne = predict()

    with open('prediction.csv', mode='w') as prediction_file:
        csv_writer = csv.writer(prediction_file)

        csv_writer.writerow(['dates', 'prediction', 'sales'])

        for i in range(len(colonne['dates'])):
            csv_writer.writerow([
                colonne['dates'][i],
                colonne['prediction'][i],
                colonne['sales'][i],
            ])

def get_prediction_from_file():
    with open('prediction.csv', mode='r') as csv_file:
        reader = csv.reader(csv_file)

        i = 0

        results = {
            'dates': [],
            'prediction': [],
            'sales': []
        }

        for row in reader:
            if i > 0 and len(row) > 0:
                print(row)
                results['dates'].append(row[0])
                results['prediction'].append(row[1])
                results['sales'].append(row[2])

            i += 1

        return results

if __name__ == '__main__':
    get_prediction_from_file()
